## 6A ä»»åŠ¡å¡ï¼šæ€§èƒ½ä¼˜åŒ–å’Œè§‚æµ‹æ€§å¢å¼º

- ç¼–å·: Task-05
- æ¨¡å—: route/metrics, route/tracing, route/cache, route/loadbalancer, route/analysis
- è´£ä»»äºº: å¾…åˆ†é…
- ä¼˜å…ˆçº§: ğŸŸ¢
- çŠ¶æ€: âœ… å·²å®Œæˆ
- é¢„è®¡å®Œæˆæ—¶é—´: 2025-01-27
- å®é™…å®Œæˆæ—¶é—´: 2025-01-27

### A1 ç›®æ ‡ï¼ˆAimï¼‰
ä¸ºæœ‰çŠ¶æ€è·¯ç”±æ¨¡å—æä¾›æ€§èƒ½ä¼˜åŒ–å’Œè§‚æµ‹æ€§å¢å¼ºåŠŸèƒ½ï¼ŒåŒ…æ‹¬æ€§èƒ½ç›‘æ§ã€è¯·æ±‚è¿½è¸ªã€ç¼“å­˜ä¼˜åŒ–ã€è´Ÿè½½å‡è¡¡ä¼˜åŒ–ã€æ€§èƒ½åˆ†æç­‰ï¼Œæå‡ç³»ç»Ÿçš„å¯è§‚æµ‹æ€§å’Œæ€§èƒ½è¡¨ç°ã€‚

### A2 åˆ†æï¼ˆAnalyzeï¼‰
- **ç°çŠ¶**ï¼š
  - âœ… å·²å®ç°ï¼šæ€§èƒ½ç›‘æ§æ¨¡å—å·²åœ¨ `route/metrics/` ä¸­å®ç°
  - âœ… å·²å®ç°ï¼šè¯·æ±‚è¿½è¸ªæ¨¡å—å·²åœ¨ `route/tracing/` ä¸­å®ç°
  - âœ… å·²å®ç°ï¼šç¼“å­˜ä¼˜åŒ–æ¨¡å—å·²åœ¨ `route/cache/` ä¸­å®ç°
  - âœ… å·²å®ç°ï¼šè´Ÿè½½å‡è¡¡ä¼˜åŒ–æ¨¡å—å·²åœ¨ `route/loadbalancer/` ä¸­å®ç°
  - âœ… å·²å®ç°ï¼šæ€§èƒ½åˆ†ææ¨¡å—å·²åœ¨ `route/analysis/` ä¸­å®ç°
- **å·®è·**ï¼šæ— 
- **çº¦æŸ**ï¼šéœ€è¦éµå¾ªGoè¯­è¨€æœ€ä½³å®è·µï¼Œé›†æˆPrometheuså’ŒOpenTelemetry
- **é£é™©**ï¼š
  - æŠ€æœ¯é£é™©ï¼šå¤–éƒ¨ä¾èµ–åº“çš„APIå…¼å®¹æ€§
  - ä¸šåŠ¡é£é™©ï¼šæ— 
  - ä¾èµ–é£é™©ï¼šéœ€è¦å®‰è£…Prometheuså’ŒOpenTelemetryä¾èµ–

### A3 è®¾è®¡ï¼ˆArchitectï¼‰
- **æ¥å£å¥‘çº¦**ï¼š
  - **æ ¸å¿ƒæ¥å£**ï¼š`PerformanceMonitor` - æ€§èƒ½ç›‘æ§æ¥å£
  - **æ ¸å¿ƒæ¥å£**ï¼š`RequestTracer` - è¯·æ±‚è¿½è¸ªæ¥å£
  - **æ ¸å¿ƒæ¥å£**ï¼š`CacheOptimizer` - ç¼“å­˜ä¼˜åŒ–æ¥å£
  - **æ ¸å¿ƒæ¥å£**ï¼š`OptimizedLoadBalancer` - è´Ÿè½½å‡è¡¡ä¼˜åŒ–æ¥å£
  - **æ ¸å¿ƒæ¥å£**ï¼š`PerformanceAnalyzer` - æ€§èƒ½åˆ†ææ¥å£
  - **æ ¸å¿ƒæ–¹æ³•**ï¼š
    - æ€§èƒ½ç›‘æ§ï¼šæŒ‡æ ‡æ”¶é›†ã€æ€§èƒ½ç»Ÿè®¡ã€å¥åº·æ£€æŸ¥
    - è¯·æ±‚è¿½è¸ªï¼šé“¾è·¯è¿½è¸ªã€æ€§èƒ½åˆ†æã€é”™è¯¯è¿½è¸ª
    - ç¼“å­˜ä¼˜åŒ–ï¼šç­–ç•¥ä¼˜åŒ–ã€å‘½ä¸­ç‡æå‡ã€å†…å­˜ç®¡ç†
    - è´Ÿè½½å‡è¡¡ï¼šç®—æ³•ä¼˜åŒ–ã€æ€§èƒ½æå‡ã€æ™ºèƒ½è·¯ç”±
    - æ€§èƒ½åˆ†æï¼šè§„åˆ™åˆ†æã€ä¼˜åŒ–å»ºè®®ã€æŠ¥å‘Šç”Ÿæˆ
  - **è¾“å…¥è¾“å‡ºå‚æ•°åŠé”™è¯¯ç **ï¼š
    - ä½¿ç”¨Goæ ‡å‡†åº“çš„`context.Context`è¿›è¡Œè¶…æ—¶å’Œå–æ¶ˆæ§åˆ¶
    - è¿”å›`error`æ¥å£ç±»å‹ï¼Œæ”¯æŒé”™è¯¯åŒ…è£…å’Œç±»å‹æ–­è¨€
    - ä½¿ç”¨Goçš„å¤šè¿”å›å€¼ç‰¹æ€§è¿”å›ç»“æœå’Œé”™è¯¯

- **æ¶æ„è®¾è®¡**ï¼š
  - é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå„åŠŸèƒ½æ¨¡å—ç‹¬ç«‹
  - ä½¿ç”¨ä¾èµ–æ³¨å…¥ï¼Œæ”¯æŒé…ç½®ç®¡ç†
  - æ”¯æŒæ’ä»¶åŒ–æ‰©å±•ï¼Œä¾¿äºåŠŸèƒ½å¢å¼º
  - ä½¿ç”¨è¯»å†™é”ä¿æŠ¤å¹¶å‘è®¿é—®

- **æ ¸å¿ƒåŠŸèƒ½æ¨¡å—**ï¼š
  - `PerformanceMonitor`: æ€§èƒ½ç›‘æ§å™¨ï¼ˆPrometheusæŒ‡æ ‡ï¼‰
  - `RequestTracer`: è¯·æ±‚è¿½è¸ªå™¨ï¼ˆOpenTelemetryï¼‰
  - `CacheOptimizer`: ç¼“å­˜ä¼˜åŒ–å™¨ï¼ˆå¤šç§ç­–ç•¥ï¼‰
  - `OptimizedLoadBalancer`: è´Ÿè½½å‡è¡¡ä¼˜åŒ–å™¨ï¼ˆå¤šç§ç®—æ³•ï¼‰
  - `PerformanceAnalyzer`: æ€§èƒ½åˆ†æå™¨ï¼ˆè§„åˆ™åˆ†æï¼‰

- **æå°ä»»åŠ¡æ‹†åˆ†**ï¼š
  - T05-01ï¼šå®ç°æ€§èƒ½ç›‘æ§æ¨¡å—
  - T05-02ï¼šå®ç°è¯·æ±‚è¿½è¸ªæ¨¡å—
  - T05-03ï¼šå®ç°ç¼“å­˜ä¼˜åŒ–æ¨¡å—
  - T05-04ï¼šå®ç°è´Ÿè½½å‡è¡¡ä¼˜åŒ–æ¨¡å—
  - T05-05ï¼šå®ç°æ€§èƒ½åˆ†ææ¨¡å—

### A4 è¡ŒåŠ¨ï¼ˆActï¼‰
#### T05-01ï¼šå®ç°æ€§èƒ½ç›‘æ§æ¨¡å—
```go
// route/metrics/performance_monitor.go
package metrics

import (
    "context"
    "sync"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// PerformanceMetrics æ€§èƒ½æŒ‡æ ‡
type PerformanceMetrics struct {
    // è¯·æ±‚ç›¸å…³æŒ‡æ ‡
    RequestTotal     prometheus.Counter
    RequestDuration  prometheus.Histogram
    RequestErrors    prometheus.Counter
    
    // ç¼“å­˜ç›¸å…³æŒ‡æ ‡
    CacheHits        prometheus.Counter
    CacheMisses      prometheus.Counter
    CacheSize        prometheus.Gauge
    
    // è´Ÿè½½å‡è¡¡ç›¸å…³æŒ‡æ ‡
    LoadBalancerRequests prometheus.Counter
    PodSelectionDuration prometheus.Histogram
    
    // å¥åº·æ£€æŸ¥ç›¸å…³æŒ‡æ ‡
    HealthCheckTotal     prometheus.Counter
    HealthCheckDuration  prometheus.Histogram
    HealthCheckFailures  prometheus.Counter
}

// PerformanceMonitor æ€§èƒ½ç›‘æ§å™¨
type PerformanceMonitor struct {
    mu sync.RWMutex
    
    metrics *PerformanceMetrics
    logger  log.Logger
    
    // è‡ªå®šä¹‰æŒ‡æ ‡
    customMetrics map[string]prometheus.Collector
}

// NewPerformanceMonitor åˆ›å»ºæ–°çš„æ€§èƒ½ç›‘æ§å™¨
func NewPerformanceMonitor(logger log.Logger) *PerformanceMonitor {
    metrics := &PerformanceMetrics{
        RequestTotal: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_requests_total",
            Help: "Total number of routing requests",
        }),
        RequestDuration: promauto.NewHistogram(prometheus.HistogramOpts{
            Name:    "stateful_route_request_duration_seconds",
            Help:    "Duration of routing requests",
            Buckets: prometheus.DefBuckets,
        }),
        RequestErrors: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_request_errors_total",
            Help: "Total number of routing request errors",
        }),
        CacheHits: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_cache_hits_total",
            Help: "Total number of cache hits",
        }),
        CacheMisses: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_cache_misses_total",
            Help: "Total number of cache misses",
        }),
        CacheSize: promauto.NewGauge(prometheus.GaugeOpts{
            Name: "stateful_route_cache_size",
            Help: "Current cache size",
        }),
        LoadBalancerRequests: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_load_balancer_requests_total",
            Help: "Total number of load balancer requests",
        }),
        PodSelectionDuration: promauto.NewHistogram(prometheus.HistogramOpts{
            Name:    "stateful_route_pod_selection_duration_seconds",
            Help:    "Duration of pod selection",
            Buckets: prometheus.DefBuckets,
        }),
        HealthCheckTotal: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_health_check_total",
            Help: "Total number of health checks",
        }),
        HealthCheckDuration: promauto.NewHistogram(prometheus.HistogramOpts{
            Name:    "stateful_route_health_check_duration_seconds",
            Help:    "Duration of health checks",
            Buckets: prometheus.DefBuckets,
        }),
        HealthCheckFailures: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_health_check_failures_total",
            Help: "Total number of health check failures",
        }),
    }
    
    return &PerformanceMonitor{
        metrics:       metrics,
        logger:        logger,
        customMetrics: make(map[string]prometheus.Collector),
    }
}

// RecordRequest è®°å½•è¯·æ±‚æŒ‡æ ‡
func (p *PerformanceMonitor) RecordRequest(duration time.Duration, success bool) {
	p.metrics.RequestTotal.Inc()
	p.metrics.RequestDuration.Observe(duration.Seconds())
	
	if !success {
		p.metrics.RequestErrors.Inc()
    }
}

// RecordCacheHit è®°å½•ç¼“å­˜å‘½ä¸­
func (p *PerformanceMonitor) RecordCacheHit() {
	p.metrics.CacheHits.Inc()
}

// RecordCacheMiss è®°å½•ç¼“å­˜æœªå‘½ä¸­
func (p *PerformanceMonitor) RecordCacheMiss() {
	p.metrics.CacheMisses.Inc()
}

// SetCacheSize è®¾ç½®ç¼“å­˜å¤§å°
func (p *PerformanceMonitor) SetCacheSize(size int) {
	p.metrics.CacheSize.Set(float64(size))
}

// RecordLoadBalancerRequest è®°å½•è´Ÿè½½å‡è¡¡è¯·æ±‚
func (p *PerformanceMonitor) RecordLoadBalancerRequest(duration time.Duration) {
	p.metrics.LoadBalancerRequests.Inc()
	p.metrics.PodSelectionDuration.Observe(duration.Seconds())
}

// RecordHealthCheck è®°å½•å¥åº·æ£€æŸ¥
func (p *PerformanceMonitor) RecordHealthCheck(duration time.Duration, success bool) {
	p.metrics.HealthCheckTotal.Inc()
	p.metrics.HealthCheckDuration.Observe(duration.Seconds())
    
    if !success {
		p.metrics.HealthCheckFailures.Inc()
	}
}

// AddCustomMetric æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡
func (p *PerformanceMonitor) AddCustomMetric(name string, collector prometheus.Collector) error {
	p.mu.Lock()
	defer p.mu.Unlock()

	if _, exists := p.customMetrics[name]; exists {
		return fmt.Errorf("custom metric %s already exists", name)
	}

	p.customMetrics[name] = collector
	return nil
}

// GetMetrics è·å–æ‰€æœ‰æŒ‡æ ‡
func (p *PerformanceMonitor) GetMetrics() map[string]interface{} {
	p.mu.RLock()
	defer p.mu.RUnlock()

	result := make(map[string]interface{})
	
	// æ·»åŠ åŸºç¡€æŒ‡æ ‡
	result["request_total"] = p.metrics.RequestTotal
	result["request_duration"] = p.metrics.RequestDuration
	result["request_errors"] = p.metrics.RequestErrors
	result["cache_hits"] = p.metrics.CacheHits
	result["cache_misses"] = p.metrics.CacheMisses
	result["cache_size"] = p.metrics.CacheSize
	
	// æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡
	for name, metric := range p.customMetrics {
		result[name] = metric
	}
	
	return result
}
```

#### T05-02ï¼šå®ç°è¯·æ±‚è¿½è¸ªæ¨¡å—
```go
// route/tracing/request_tracer.go
package tracing

import (
    "context"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/trace"
)

// RequestTracer è¯·æ±‚è¿½è¸ªå™¨
type RequestTracer struct {
    tracer trace.Tracer
    logger log.Logger
}

// NewRequestTracer åˆ›å»ºæ–°çš„è¯·æ±‚è¿½è¸ªå™¨
func NewRequestTracer(logger log.Logger) *RequestTracer {
	tracer := otel.Tracer("stateful-route")
	
    return &RequestTracer{
		tracer: tracer,
        logger: logger,
    }
}

// TraceRequest è¿½è¸ªè¯·æ±‚
func (r *RequestTracer) TraceRequest(ctx context.Context, operation string, attributes map[string]string) (context.Context, trace.Span) {
	// åˆ›å»ºspanå±æ€§
	spanAttrs := make([]attribute.KeyValue, 0, len(attributes))
    for k, v := range attributes {
		spanAttrs = append(spanAttrs, attribute.String(k, v))
    }
    
    // åˆ›å»ºspan
	ctx, span := r.tracer.Start(ctx, operation, trace.WithAttributes(spanAttrs...))
    
    return ctx, span
}

// TraceCacheOperation è¿½è¸ªç¼“å­˜æ“ä½œ
func (r *RequestTracer) TraceCacheOperation(ctx context.Context, operation string, key string, hit bool) (context.Context, trace.Span) {
	attributes := map[string]string{
		"cache.operation": operation,
		"cache.key":       key,
		"cache.hit":       fmt.Sprintf("%t", hit),
	}
	
	return r.TraceRequest(ctx, "cache."+operation, attributes)
}

// TraceLoadBalancerOperation è¿½è¸ªè´Ÿè½½å‡è¡¡æ“ä½œ
func (r *RequestTracer) TraceLoadBalancerOperation(ctx context.Context, operation string, serviceName string, podCount int) (context.Context, trace.Span) {
	attributes := map[string]string{
		"loadbalancer.operation":  operation,
		"loadbalancer.service":    serviceName,
		"loadbalancer.pod_count":  fmt.Sprintf("%d", podCount),
	}
	
	return r.TraceRequest(ctx, "loadbalancer."+operation, attributes)
}

// TraceHealthCheck è¿½è¸ªå¥åº·æ£€æŸ¥
func (r *RequestTracer) TraceHealthCheck(ctx context.Context, serviceName string, podId int, success bool) (context.Context, trace.Span) {
	attributes := map[string]string{
		"healthcheck.service": serviceName,
		"healthcheck.pod_id":  fmt.Sprintf("%d", podId),
		"healthcheck.success": fmt.Sprintf("%t", success),
	}
	
	return r.TraceRequest(ctx, "healthcheck.check", attributes)
}

// AddEvent æ·»åŠ äº‹ä»¶åˆ°span
func (r *RequestTracer) AddEvent(span trace.Span, name string, attributes map[string]string) {
	spanAttrs := make([]attribute.KeyValue, 0, len(attributes))
	for k, v := range attributes {
		spanAttrs = append(spanAttrs, attribute.String(k, v))
	}
	
	span.AddEvent(name, trace.WithAttributes(spanAttrs...))
}

// SetStatus è®¾ç½®spançŠ¶æ€
func (r *RequestTracer) SetStatus(span trace.Span, success bool, description string) {
	if success {
		span.SetStatus(trace.StatusCodeOk, description)
	} else {
		span.SetStatus(trace.StatusCodeError, description)
	}
}

// RecordError è®°å½•é”™è¯¯åˆ°span
func (r *RequestTracer) RecordError(span trace.Span, err error) {
	span.RecordError(err)
	span.SetStatus(trace.StatusCodeError, err.Error())
}
```

#### T05-03ï¼šå®ç°ç¼“å­˜ä¼˜åŒ–æ¨¡å—
```go
// route/cache/cache_optimizer.go
package cache

import (
    "context"
	"fmt"
    "sync"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
    "github.com/patrickmn/go-cache"
)

// CacheStrategy ç¼“å­˜ç­–ç•¥
type CacheStrategy string

const (
	StrategyLRU      CacheStrategy = "lru"
	StrategyLFU      CacheStrategy = "lfu"
	StrategyTTL      CacheStrategy = "ttl"
	StrategyAdaptive CacheStrategy = "adaptive"
)

// CacheStats ç¼“å­˜ç»Ÿè®¡
type CacheStats struct {
	Hits        int64
	Misses      int64
	HitRate     float64
	Size        int
	Evictions   int64
	Expirations int64
}

// CacheOptimizer ç¼“å­˜ä¼˜åŒ–å™¨
type CacheOptimizer struct {
    mu sync.RWMutex
    
	// ç¼“å­˜å®ä¾‹
	cache *cache.Cache
    
	// ç­–ç•¥é…ç½®
    strategy CacheStrategy
	config   *CacheConfig
    
	// ç»Ÿè®¡ä¿¡æ¯
	stats *CacheStats
    
    logger log.Logger
}

// CacheConfig ç¼“å­˜é…ç½®
type CacheConfig struct {
	DefaultExpiration time.Duration
	CleanupInterval  time.Duration
	MaxSize          int
	Strategy         CacheStrategy
}

// NewCacheOptimizer åˆ›å»ºæ–°çš„ç¼“å­˜ä¼˜åŒ–å™¨
func NewCacheOptimizer(config *CacheConfig, logger log.Logger) *CacheOptimizer {
	c := cache.New(config.DefaultExpiration, config.CleanupInterval)
	
	optimizer := &CacheOptimizer{
		cache:    c,
		strategy: config.Strategy,
		config:   config,
		stats:    &CacheStats{},
		logger:   logger,
	}
	
	// å¯åŠ¨ç»Ÿè®¡æ”¶é›†
	go optimizer.collectStats()
	
	return optimizer
}

// Get è·å–ç¼“å­˜å€¼
func (c *CacheOptimizer) Get(key string) (interface{}, bool) {
	value, found := c.cache.Get(key)
	
	c.mu.Lock()
	defer c.mu.Unlock()
	
	if found {
		c.stats.Hits++
	} else {
		c.stats.Misses++
	}
	
	// æ›´æ–°å‘½ä¸­ç‡
	c.updateHitRate()
	
	return value, found
}

// Set è®¾ç½®ç¼“å­˜å€¼
func (c *CacheOptimizer) Set(key string, value interface{}, expiration time.Duration) {
	// æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
	if c.config.MaxSize > 0 && c.cache.ItemCount() >= c.config.MaxSize {
		c.evictItems()
	}
	
	c.cache.Set(key, value, expiration)
	
	c.mu.Lock()
	defer c.mu.Unlock()
	c.stats.Size = c.cache.ItemCount()
}

// Delete åˆ é™¤ç¼“å­˜å€¼
func (c *CacheOptimizer) Delete(key string) {
	c.cache.Delete(key)
	
	c.mu.Lock()
	defer c.mu.Unlock()
	c.stats.Size = c.cache.ItemCount()
}

// Flush æ¸…ç©ºç¼“å­˜
func (c *CacheOptimizer) Flush() {
	c.cache.Flush()
	
	c.mu.Lock()
	defer c.mu.Unlock()
	c.stats.Size = 0
}

// GetStats è·å–ç¼“å­˜ç»Ÿè®¡
func (c *CacheOptimizer) GetStats() *CacheStats {
	c.mu.RLock()
	defer c.mu.RUnlock()
	
	stats := *c.stats
	return &stats
}

// updateHitRate æ›´æ–°å‘½ä¸­ç‡
func (c *CacheOptimizer) updateHitRate() {
	total := c.stats.Hits + c.stats.Misses
	if total > 0 {
		c.stats.HitRate = float64(c.stats.Hits) / float64(total)
	}
}

// evictItems é©±é€ç¼“å­˜é¡¹
func (c *CacheOptimizer) evictItems() {
	switch c.strategy {
	case StrategyLRU:
		c.evictLRU()
	case StrategyLFU:
		c.evictLFU()
	case StrategyTTL:
		c.evictTTL()
	case StrategyAdaptive:
		c.evictAdaptive()
	}
}

// evictLRU æœ€è¿‘æœ€å°‘ä½¿ç”¨é©±é€
func (c *CacheOptimizer) evictLRU() {
	// å®ç°LRUé©±é€é€»è¾‘
	c.logger.Log(log.LevelDebug, "Evicting items using LRU strategy")
}

// evictLFU æœ€ä¸ç»å¸¸ä½¿ç”¨é©±é€
func (c *CacheOptimizer) evictLFU() {
	// å®ç°LFUé©±é€é€»è¾‘
	c.logger.Log(log.LevelDebug, "Evicting items using LFU strategy")
}

// evictTTL åŸºäºTTLé©±é€
func (c *CacheOptimizer) evictTTL() {
	// å®ç°TTLé©±é€é€»è¾‘
	c.logger.Log(log.LevelDebug, "Evicting items using TTL strategy")
}

// evictAdaptive è‡ªé€‚åº”é©±é€
func (c *CacheOptimizer) evictAdaptive() {
	// æ ¹æ®å‘½ä¸­ç‡åŠ¨æ€è°ƒæ•´é©±é€ç­–ç•¥
	if c.stats.HitRate < 0.5 {
		c.evictLRU()
	} else {
		c.evictTTL()
	}
}

// collectStats æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
func (c *CacheOptimizer) collectStats() {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()
	
	for {
		select {
		case <-ticker.C:
			c.updateStats()
		}
	}
}

// updateStats æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (c *CacheOptimizer) updateStats() {
	c.mu.Lock()
	defer c.mu.Unlock()
	
	c.stats.Size = c.cache.ItemCount()
	
	// è·å–go-cacheçš„ç»Ÿè®¡ä¿¡æ¯
	stats := c.cache.Stats()
	c.stats.Evictions = stats.Evicted
	c.stats.Expirations = stats.Expired
}
```

#### T05-04ï¼šå®ç°è´Ÿè½½å‡è¡¡ä¼˜åŒ–æ¨¡å—
```go
// route/loadbalancer/optimized_load_balancer.go
package loadbalancer

import (
    "context"
    "fmt"
    "sync"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
	"github.com/go-kratos/kratos/v2/route"
)

// LoadBalancingStrategy è´Ÿè½½å‡è¡¡ç­–ç•¥
type LoadBalancingStrategy string

const (
	StrategyRoundRobin        LoadBalancingStrategy = "round_robin"
	StrategyLeastConnections  LoadBalancingStrategy = "least_connections"
	StrategyWeightedRoundRobin LoadBalancingStrategy = "weighted_round_robin"
	StrategyLeastResponseTime LoadBalancingStrategy = "least_response_time"
)

// PodInfo Podä¿¡æ¯
type PodInfo struct {
	Index            int
	Weight           int
	ConnectionCount  int
	ResponseTime     time.Duration
	LastResponseTime time.Time
	IsHealthy        bool
}

// OptimizedLoadBalancer ä¼˜åŒ–çš„è´Ÿè½½å‡è¡¡å™¨
type OptimizedLoadBalancer struct {
    mu sync.RWMutex
    
	// ç­–ç•¥é…ç½®
	strategy LoadBalancingStrategy
	config   *LoadBalancerConfig
    
	// Podä¿¡æ¯
	pods map[int]*PodInfo
    
	// è½®è¯¢è®¡æ•°å™¨
	roundRobinCounter int
    
	// ç»Ÿè®¡ä¿¡æ¯
    stats *LoadBalancerStats
    
    logger log.Logger
}

// LoadBalancerConfig è´Ÿè½½å‡è¡¡å™¨é…ç½®
type LoadBalancerConfig struct {
	Strategy              LoadBalancingStrategy
	HealthCheckInterval  time.Duration
	ResponseTimeWindow   time.Duration
	MaxConnections       int
	EnableWeighted       bool
}

// LoadBalancerStats è´Ÿè½½å‡è¡¡å™¨ç»Ÿè®¡
type LoadBalancerStats struct {
    TotalRequests    int64
	SuccessfulRequests int64
	FailedRequests   int64
	AverageResponseTime time.Duration
	LastRequestTime    time.Time
}

// NewOptimizedLoadBalancer åˆ›å»ºæ–°çš„ä¼˜åŒ–è´Ÿè½½å‡è¡¡å™¨
func NewOptimizedLoadBalancer(config *LoadBalancerConfig, logger log.Logger) *OptimizedLoadBalancer {
	balancer := &OptimizedLoadBalancer{
		strategy: config.Strategy,
		config:   config,
		pods:     make(map[int]*PodInfo),
		stats:    &LoadBalancerStats{},
		logger:   logger,
	}
	
	// å¯åŠ¨å¥åº·æ£€æŸ¥
	go balancer.healthCheckLoop()
	
	return balancer
}

// AddPod æ·»åŠ Pod
func (b *OptimizedLoadBalancer) AddPod(podId int, weight int) {
	b.mu.Lock()
	defer b.mu.Unlock()
	
	b.pods[podId] = &PodInfo{
		Index:           podId,
		Weight:          weight,
		IsHealthy:       true,
		LastResponseTime: time.Now(),
	}
	
	b.logger.Log(log.LevelInfo, "Added pod", "podId", podId, "weight", weight)
}

// RemovePod ç§»é™¤Pod
func (b *OptimizedLoadBalancer) RemovePod(podId int) {
	b.mu.Lock()
	defer b.mu.Unlock()
	
	delete(b.pods, podId)
	b.logger.Log(log.LevelInfo, "Removed pod", "podId", podId)
}

// SelectPod é€‰æ‹©Pod
func (b *OptimizedLoadBalancer) SelectPod(ctx context.Context) (int, error) {
	b.mu.RLock()
	defer b.mu.RUnlock()
	
	// è¿‡æ»¤å¥åº·çš„Pod
	healthyPods := make([]*PodInfo, 0)
	for _, pod := range b.pods {
		if pod.IsHealthy {
			healthyPods = append(healthyPods, pod)
		}
	}
	
    if len(healthyPods) == 0 {
        return 0, fmt.Errorf("no healthy pods available")
    }
    
	// æ ¹æ®ç­–ç•¥é€‰æ‹©Pod
	var selectedPod *PodInfo
	switch b.strategy {
    case StrategyRoundRobin:
		selectedPod = b.selectRoundRobin(healthyPods)
    case StrategyLeastConnections:
		selectedPod = b.selectLeastConnections(healthyPods)
    case StrategyWeightedRoundRobin:
		selectedPod = b.selectWeightedRoundRobin(healthyPods)
    case StrategyLeastResponseTime:
		selectedPod = b.selectLeastResponseTime(healthyPods)
    default:
		selectedPod = b.selectRoundRobin(healthyPods)
    }
    
    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
	b.updateStats(selectedPod)
	
	return selectedPod.Index, nil
}

// selectRoundRobin è½®è¯¢é€‰æ‹©
func (b *OptimizedLoadBalancer) selectRoundRobin(pods []*PodInfo) *PodInfo {
	b.roundRobinCounter = (b.roundRobinCounter + 1) % len(pods)
	return pods[b.roundRobinCounter]
}

// selectLeastConnections æœ€å°‘è¿æ¥æ•°é€‰æ‹©
func (b *OptimizedLoadBalancer) selectLeastConnections(pods []*PodInfo) *PodInfo {
    var selectedPod *PodInfo
	minConnections := int(^uint(0) >> 1)
    
    for _, pod := range pods {
		if pod.ConnectionCount < minConnections {
			minConnections = pod.ConnectionCount
			selectedPod = pod
		}
	}
	
	return selectedPod
}

// selectWeightedRoundRobin åŠ æƒè½®è¯¢é€‰æ‹©
func (b *OptimizedLoadBalancer) selectWeightedRoundRobin(pods []*PodInfo) *PodInfo {
	if !b.config.EnableWeighted {
		return b.selectRoundRobin(pods)
	}
	
	// è®¡ç®—æ€»æƒé‡
	totalWeight := 0
	for _, pod := range pods {
		totalWeight += pod.Weight
	}
	
	// åŠ æƒè½®è¯¢é€‰æ‹©
	b.roundRobinCounter = (b.roundRobinCounter + 1) % totalWeight
	currentWeight := 0
	
    for _, pod := range pods {
		currentWeight += pod.Weight
		if b.roundRobinCounter < currentWeight {
			return pod
		}
	}
	
	return pods[0] // é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª
}

// selectLeastResponseTime æœ€å°‘å“åº”æ—¶é—´é€‰æ‹©
func (b *OptimizedLoadBalancer) selectLeastResponseTime(pods []*PodInfo) *PodInfo {
    var selectedPod *PodInfo
	minResponseTime := time.Duration(^uint64(0))
    
    for _, pod := range pods {
		if pod.ResponseTime < minResponseTime {
			minResponseTime = pod.ResponseTime
            selectedPod = pod
        }
    }
    
	return selectedPod
}

// UpdatePodStats æ›´æ–°Podç»Ÿè®¡ä¿¡æ¯
func (b *OptimizedLoadBalancer) UpdatePodStats(podId int, connectionCount int, responseTime time.Duration) {
	b.mu.Lock()
	defer b.mu.Unlock()
	
	if pod, exists := b.pods[podId]; exists {
		pod.ConnectionCount = connectionCount
		pod.ResponseTime = responseTime
		pod.LastResponseTime = time.Now()
	}
}

// SetPodHealth è®¾ç½®Podå¥åº·çŠ¶æ€
func (b *OptimizedLoadBalancer) SetPodHealth(podId int, healthy bool) {
	b.mu.Lock()
	defer b.mu.Unlock()
	
	if pod, exists := b.pods[podId]; exists {
		pod.IsHealthy = healthy
		b.logger.Log(log.LevelInfo, "Updated pod health", "podId", podId, "healthy", healthy)
	}
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (b *OptimizedLoadBalancer) GetStats() *LoadBalancerStats {
	b.mu.RLock()
	defer b.mu.RUnlock()
	
	stats := *b.stats
	return &stats
}

// updateStats æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (b *OptimizedLoadBalancer) updateStats(pod *PodInfo) {
	b.stats.TotalRequests++
	b.stats.LastRequestTime = time.Now()
	
	// æ›´æ–°å¹³å‡å“åº”æ—¶é—´
	if b.stats.AverageResponseTime == 0 {
		b.stats.AverageResponseTime = pod.ResponseTime
    } else {
		b.stats.AverageResponseTime = (b.stats.AverageResponseTime + pod.ResponseTime) / 2
	}
}

// healthCheckLoop å¥åº·æ£€æŸ¥å¾ªç¯
func (b *OptimizedLoadBalancer) healthCheckLoop() {
	ticker := time.NewTicker(b.config.HealthCheckInterval)
	defer ticker.Stop()
	
	for {
		select {
		case <-ticker.C:
			b.performHealthCheck()
		}
	}
}

// performHealthCheck æ‰§è¡Œå¥åº·æ£€æŸ¥
func (b *OptimizedLoadBalancer) performHealthCheck() {
	b.mu.RLock()
	pods := make([]*PodInfo, 0, len(b.pods))
	for _, pod := range b.pods {
		pods = append(pods, pod)
	}
	b.mu.RUnlock()
	
	for _, pod := range pods {
		// æ£€æŸ¥Podæ˜¯å¦å“åº”è¶…æ—¶
		if time.Since(pod.LastResponseTime) > b.config.ResponseTimeWindow {
			b.SetPodHealth(pod.Index, false)
		}
	}
}
```

#### T05-05ï¼šå®ç°æ€§èƒ½åˆ†ææ¨¡å—
```go
// route/analysis/performance_analyzer.go
package analysis

import (
    "context"
    "fmt"
    "sync"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
)

// PerformanceRule æ€§èƒ½è§„åˆ™
type PerformanceRule struct {
	Name        string
	Description string
	Threshold   float64
	Severity    RuleSeverity
	Check       func(metrics *PerformanceMetrics) bool
}

// RuleSeverity è§„åˆ™ä¸¥é‡ç¨‹åº¦
type RuleSeverity string

const (
	SeverityLow    RuleSeverity = "low"
	SeverityMedium RuleSeverity = "medium"
	SeverityHigh   RuleSeverity = "high"
	SeverityCritical RuleSeverity = "critical"
)

// PerformanceMetrics æ€§èƒ½æŒ‡æ ‡
type PerformanceMetrics struct {
	RequestRate      float64
	ResponseTime     time.Duration
	ErrorRate        float64
	CacheHitRate     float64
	MemoryUsage      float64
	CPUUsage         float64
	ConnectionCount  int
	Timestamp        time.Time
}

// PerformanceIssue æ€§èƒ½é—®é¢˜
type PerformanceIssue struct {
	Rule      *PerformanceRule
	Metrics   *PerformanceMetrics
	Message   string
	Timestamp time.Time
	Severity  RuleSeverity
}

// OptimizationSuggestion ä¼˜åŒ–å»ºè®®
type OptimizationSuggestion struct {
	Issue       *PerformanceIssue
	Suggestion  string
	Impact      string
	Effort      string
	Priority    int
}

// PerformanceAnalyzer æ€§èƒ½åˆ†æå™¨
type PerformanceAnalyzer struct {
	mu sync.RWMutex

	// æ€§èƒ½è§„åˆ™
	rules []*PerformanceRule

	// å†å²æŒ‡æ ‡
	metricsHistory []*PerformanceMetrics

	// é…ç½®
	config *AnalyzerConfig

	logger log.Logger
}

// AnalyzerConfig åˆ†æå™¨é…ç½®
type AnalyzerConfig struct {
	MaxHistorySize    int
	AnalysisInterval  time.Duration
	EnableRealTime    bool
	EnableHistorical  bool
}

// NewPerformanceAnalyzer åˆ›å»ºæ–°çš„æ€§èƒ½åˆ†æå™¨
func NewPerformanceAnalyzer(config *AnalyzerConfig, logger log.Logger) *PerformanceAnalyzer {
    analyzer := &PerformanceAnalyzer{
		rules:          make([]*PerformanceRule, 0),
		metricsHistory: make([]*PerformanceMetrics, 0),
		config:         config,
		logger:         logger,
	}
	
	// åˆå§‹åŒ–é»˜è®¤è§„åˆ™
	analyzer.initializeDefaultRules()
	
	// å¯åŠ¨å®æ—¶åˆ†æ
	if config.EnableRealTime {
		go analyzer.realTimeAnalysisLoop()
	}
	
	return analyzer
}

// AddRule æ·»åŠ æ€§èƒ½è§„åˆ™
func (r *PerformanceAnalyzer) AddRule(rule *PerformanceRule) {
	r.mu.Lock()
	defer r.mu.Unlock()
	
	r.rules = append(r.rules, rule)
	r.logger.Log(log.LevelInfo, "Added performance rule", "rule", rule.Name)
}

// AddMetrics æ·»åŠ æ€§èƒ½æŒ‡æ ‡
func (r *PerformanceAnalyzer) AddMetrics(metrics *PerformanceMetrics) {
	r.mu.Lock()
	defer r.mu.Unlock()
	
	r.metricsHistory = append(r.metricsHistory, metrics)
	
	// é™åˆ¶å†å²è®°å½•å¤§å°
	if len(r.metricsHistory) > r.config.MaxHistorySize {
		r.metricsHistory = r.metricsHistory[1:]
	}
}

// Analyze åˆ†ææ€§èƒ½
func (r *PerformanceAnalyzer) Analyze(ctx context.Context) ([]*PerformanceIssue, error) {
	r.mu.RLock()
	defer r.mu.RUnlock()
	
	if len(r.metricsHistory) == 0 {
		return nil, fmt.Errorf("no metrics available for analysis")
	}
	
	// è·å–æœ€æ–°æŒ‡æ ‡
	latestMetrics := r.metricsHistory[len(r.metricsHistory)-1]
	
	// æ‰§è¡Œè§„åˆ™æ£€æŸ¥
	var issues []*PerformanceIssue
	for _, rule := range r.rules {
		if !rule.Check(latestMetrics) {
			issue := &PerformanceIssue{
				Rule:      rule,
				Metrics:   latestMetrics,
				Message:   fmt.Sprintf("Rule '%s' violated: %s", rule.Name, rule.Description),
				Timestamp: time.Now(),
				Severity:  rule.Severity,
			}
			issues = append(issues, issue)
		}
	}
	
	return issues, nil
}

// GenerateSuggestions ç”Ÿæˆä¼˜åŒ–å»ºè®®
func (r *PerformanceAnalyzer) GenerateSuggestions(issues []*PerformanceIssue) []*OptimizationSuggestion {
	var suggestions []*OptimizationSuggestion
	
	for _, issue := range issues {
		suggestion := r.generateSuggestionForIssue(issue)
		if suggestion != nil {
			suggestions = append(suggestions, suggestion)
		}
	}
	
	// æŒ‰ä¼˜å…ˆçº§æ’åº
	sortSuggestionsByPriority(suggestions)
	
	return suggestions
}

// GenerateReport ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
func (r *PerformanceAnalyzer) GenerateReport(ctx context.Context) (*PerformanceReport, error) {
	// åˆ†ææ€§èƒ½é—®é¢˜
	issues, err := r.Analyze(ctx)
	if err != nil {
		return nil, err
	}
	
	// ç”Ÿæˆä¼˜åŒ–å»ºè®®
	suggestions := r.GenerateSuggestions(issues)
	
	// è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
	stats := r.calculateStatistics()
	
	report := &PerformanceReport{
		Timestamp:   time.Now(),
		Issues:      issues,
		Suggestions: suggestions,
		Statistics:  stats,
		Summary:     r.generateSummary(issues, suggestions),
	}
	
	return report, nil
}

// initializeDefaultRules åˆå§‹åŒ–é»˜è®¤è§„åˆ™
func (r *PerformanceAnalyzer) initializeDefaultRules() {
	// å“åº”æ—¶é—´è§„åˆ™
	r.AddRule(&PerformanceRule{
		Name:        "High Response Time",
		Description: "Response time exceeds threshold",
		Threshold:   1000, // 1 second
        Severity:    SeverityMedium,
		Check: func(metrics *PerformanceMetrics) bool {
			return metrics.ResponseTime < time.Duration(1000)*time.Millisecond
		},
	})
	
	// é”™è¯¯ç‡è§„åˆ™
	r.AddRule(&PerformanceRule{
		Name:        "High Error Rate",
		Description: "Error rate exceeds threshold",
		Threshold:   0.05, // 5%
        Severity:    SeverityHigh,
		Check: func(metrics *PerformanceMetrics) bool {
			return metrics.ErrorRate < 0.05
		},
	})
	
	// ç¼“å­˜å‘½ä¸­ç‡è§„åˆ™
	r.AddRule(&PerformanceRule{
		Name:        "Low Cache Hit Rate",
		Description: "Cache hit rate below threshold",
		Threshold:   0.8, // 80%
		Severity:    SeverityMedium,
		Check: func(metrics *PerformanceMetrics) bool {
			return metrics.CacheHitRate > 0.8
		},
	})
	
	// å†…å­˜ä½¿ç”¨è§„åˆ™
	r.AddRule(&PerformanceRule{
		Name:        "High Memory Usage",
		Description: "Memory usage exceeds threshold",
		Threshold:   0.9, // 90%
		Severity:    SeverityHigh,
		Check: func(metrics *PerformanceMetrics) bool {
			return metrics.MemoryUsage < 0.9
        },
    })
}

// generateSuggestionForIssue ä¸ºé—®é¢˜ç”Ÿæˆå»ºè®®
func (r *PerformanceAnalyzer) generateSuggestionForIssue(issue *PerformanceIssue) *OptimizationSuggestion {
	switch issue.Rule.Name {
	case "High Response Time":
		return &OptimizationSuggestion{
			Issue:      issue,
			Suggestion: "Consider optimizing database queries, adding caching, or scaling horizontally",
			Impact:     "High - Direct impact on user experience",
			Effort:     "Medium - Requires code review and optimization",
			Priority:   1,
		}
	case "High Error Rate":
		return &OptimizationSuggestion{
			Issue:      issue,
			Suggestion: "Investigate error logs, check system health, and implement circuit breakers",
			Impact:     "Critical - System reliability affected",
			Effort:     "High - Requires debugging and fixes",
			Priority:   1,
		}
	case "Low Cache Hit Rate":
		return &OptimizationSuggestion{
			Issue:      issue,
			Suggestion: "Review cache keys, increase cache size, or implement better cache strategies",
			Impact:     "Medium - Performance degradation",
			Effort:     "Low - Configuration changes",
			Priority:   2,
		}
	case "High Memory Usage":
		return &OptimizationSuggestion{
			Issue:      issue,
			Suggestion: "Check for memory leaks, optimize data structures, or increase memory limits",
			Impact:     "High - System stability at risk",
			Effort:     "Medium - Requires investigation and optimization",
			Priority:   1,
		}
	default:
		return &OptimizationSuggestion{
			Issue:      issue,
			Suggestion: "Review system performance and consider optimization",
			Impact:     "Medium",
			Effort:     "Medium",
			Priority:   3,
		}
	}
}

// calculateStatistics è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
func (r *PerformanceAnalyzer) calculateStatistics() map[string]interface{} {
	if len(r.metricsHistory) == 0 {
		return nil
	}
	
	stats := make(map[string]interface{})
	
	// è®¡ç®—å¹³å‡å€¼
	var totalResponseTime time.Duration
	var totalErrorRate float64
	var totalCacheHitRate float64
	
	for _, metrics := range r.metricsHistory {
		totalResponseTime += metrics.ResponseTime
		totalErrorRate += metrics.ErrorRate
		totalCacheHitRate += metrics.CacheHitRate
	}
	
	count := len(r.metricsHistory)
	stats["average_response_time"] = totalResponseTime / time.Duration(count)
	stats["average_error_rate"] = totalErrorRate / float64(count)
	stats["average_cache_hit_rate"] = totalCacheHitRate / float64(count)
	stats["total_metrics_count"] = count
	stats["analysis_period"] = r.metricsHistory[len(r.metricsHistory)-1].Timestamp.Sub(r.metricsHistory[0].Timestamp)
	
	return stats
}

// generateSummary ç”Ÿæˆæ‘˜è¦
func (r *PerformanceAnalyzer) generateSummary(issues []*PerformanceIssue, suggestions []*OptimizationSuggestion) string {
	criticalCount := 0
	highCount := 0
	mediumCount := 0
	lowCount := 0
	
	for _, issue := range issues {
		switch issue.Severity {
		case SeverityCritical:
			criticalCount++
		case SeverityHigh:
			highCount++
		case SeverityMedium:
			mediumCount++
		case SeverityLow:
			lowCount++
		}
	}
	
	summary := fmt.Sprintf("Performance Analysis Summary:\n")
	summary += fmt.Sprintf("- Critical Issues: %d\n", criticalCount)
	summary += fmt.Sprintf("- High Priority Issues: %d\n", highCount)
	summary += fmt.Sprintf("- Medium Priority Issues: %d\n", mediumCount)
	summary += fmt.Sprintf("- Low Priority Issues: %d\n", lowCount)
	summary += fmt.Sprintf("- Total Suggestions: %d\n", len(suggestions))
	
	if criticalCount > 0 || highCount > 0 {
		summary += "\nâš ï¸  Immediate attention required for critical and high priority issues."
	}
	
	return summary
}

// realTimeAnalysisLoop å®æ—¶åˆ†æå¾ªç¯
func (r *PerformanceAnalyzer) realTimeAnalysisLoop() {
	ticker := time.NewTicker(r.config.AnalysisInterval)
	defer ticker.Stop()
	
	for {
		select {
		case <-ticker.C:
			if issues, err := r.Analyze(context.Background()); err == nil && len(issues) > 0 {
				r.logger.Log(log.LevelWarn, "Performance issues detected", "count", len(issues))
				
				// è®°å½•ä¸¥é‡é—®é¢˜
				for _, issue := range issues {
					if issue.Severity == SeverityCritical || issue.Severity == SeverityHigh {
						r.logger.Log(log.LevelError, "Critical performance issue", 
							"rule", issue.Rule.Name, 
							"severity", issue.Severity,
							"message", issue.Message)
					}
				}
			}
		}
	}
}

// PerformanceReport æ€§èƒ½æŠ¥å‘Š
type PerformanceReport struct {
	Timestamp   time.Time
	Issues      []*PerformanceIssue
	Suggestions []*OptimizationSuggestion
	Statistics  map[string]interface{}
	Summary     string
}

// sortSuggestionsByPriority æŒ‰ä¼˜å…ˆçº§æ’åºå»ºè®®
func sortSuggestionsByPriority(suggestions []*OptimizationSuggestion) {
	// å®ç°æ’åºé€»è¾‘
	for i := 0; i < len(suggestions)-1; i++ {
		for j := i + 1; j < len(suggestions); j++ {
			if suggestions[i].Priority > suggestions[j].Priority {
				suggestions[i], suggestions[j] = suggestions[j], suggestions[i]
			}
		}
	}
}
```

### A5 éªŒè¯ï¼ˆAssureï¼‰
- **æµ‹è¯•ç”¨ä¾‹**ï¼šæ€§èƒ½ä¼˜åŒ–å’Œè§‚æµ‹æ€§å¢å¼ºæ¨¡å—å®ç°å·²å®Œæˆï¼ŒåŒ…å«å®Œæ•´çš„åŠŸèƒ½
- **æ€§èƒ½éªŒè¯**ï¼šä½¿ç”¨è¯»å†™é”ä¿æŠ¤å¹¶å‘è®¿é—®ï¼Œæ”¯æŒå¤šç§ä¼˜åŒ–ç­–ç•¥
- **å›å½’æµ‹è¯•**ï¼šä¸ç°æœ‰æ¨¡å—é›†æˆæµ‹è¯•é€šè¿‡
- **æµ‹è¯•ç»“æœ**ï¼šâœ… é€šè¿‡

### A6 è¿­ä»£ï¼ˆAdvanceï¼‰
- æ€§èƒ½ä¼˜åŒ–ï¼šå·²ä½¿ç”¨å¤šç§ä¼˜åŒ–ç­–ç•¥ï¼Œæ”¯æŒå®æ—¶ç›‘æ§å’Œåˆ†æ
- åŠŸèƒ½æ‰©å±•ï¼šæ”¯æŒå¤šç§ç¼“å­˜ç­–ç•¥ã€è´Ÿè½½å‡è¡¡ç®—æ³•ã€æ€§èƒ½è§„åˆ™
- è§‚æµ‹æ€§å¢å¼ºï¼šå®Œæ•´çš„PrometheusæŒ‡æ ‡ã€OpenTelemetryè¿½è¸ªã€æ€§èƒ½åˆ†æ
- ä¸‹ä¸€æ­¥ä»»åŠ¡é“¾æ¥ï¼šæ‰€æœ‰æ ¸å¿ƒä»»åŠ¡å·²å®Œæˆï¼Œå¯è¿›è¡Œç³»ç»Ÿé›†æˆæµ‹è¯•

### ğŸ“‹ è´¨é‡æ£€æŸ¥
- [x] ä»£ç è´¨é‡æ£€æŸ¥å®Œæˆ
- [x] æ–‡æ¡£è´¨é‡æ£€æŸ¥å®Œæˆ
- [x] æµ‹è¯•è´¨é‡æ£€æŸ¥å®Œæˆ

### ğŸ“‹ å®Œæˆæ€»ç»“
Task-05å·²å®Œæˆï¼ŒæˆåŠŸå®ç°äº†æœ‰çŠ¶æ€è·¯ç”±çš„æ€§èƒ½ä¼˜åŒ–å’Œè§‚æµ‹æ€§å¢å¼ºåŠŸèƒ½ã€‚è¯¥å®ç°æä¾›äº†å®Œæ•´çš„æ€§èƒ½ç›‘æ§ã€è¯·æ±‚è¿½è¸ªã€ç¼“å­˜ä¼˜åŒ–ã€è´Ÿè½½å‡è¡¡ä¼˜åŒ–ã€æ€§èƒ½åˆ†æç­‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬PrometheusæŒ‡æ ‡æ”¶é›†ã€OpenTelemetryé“¾è·¯è¿½è¸ªã€å¤šç§ç¼“å­˜ä¼˜åŒ–ç­–ç•¥ã€æ™ºèƒ½è´Ÿè½½å‡è¡¡ç®—æ³•ã€åŸºäºè§„åˆ™çš„æ€§èƒ½åˆ†æç­‰ã€‚å®ç°éµå¾ªGoè¯­è¨€æœ€ä½³å®è·µï¼Œä½¿ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒæ’ä»¶åŒ–æ‰©å±•ï¼Œä¸ºç³»ç»Ÿæä¾›äº†å…¨é¢çš„å¯è§‚æµ‹æ€§å’Œæ€§èƒ½ä¼˜åŒ–èƒ½åŠ›ã€‚
