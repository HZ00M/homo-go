## 6A ä»»åŠ¡å¡ï¼šæ€§èƒ½ä¼˜åŒ–å’Œè§‚æµ‹æ€§å¢å¼º

- ç¼–å·: Task-06
- æ¨¡å—: stateful-route
- è´£ä»»äºº: å¾…åˆ†é…
- ä¼˜å…ˆçº§: ğŸŸ¢ ä½
- çŠ¶æ€: âŒ æœªå¼€å§‹
- é¢„è®¡å®Œæˆæ—¶é—´: å¾…å®š
- å®é™…å®Œæˆæ—¶é—´: -

### A1 ç›®æ ‡ï¼ˆAimï¼‰
å¯¹æœ‰çŠ¶æ€è·¯ç”±æ¨¡å—è¿›è¡Œæ€§èƒ½ä¼˜åŒ–å’Œè§‚æµ‹æ€§å¢å¼ºï¼Œæå‡ç³»ç»Ÿæ€§èƒ½ã€å¯è§‚æµ‹æ€§å’Œå¯ç»´æŠ¤æ€§ï¼ŒåŒ…æ‹¬ç¼“å­˜ä¼˜åŒ–ã€ç®—æ³•ä¼˜åŒ–ã€ç›‘æ§æŒ‡æ ‡ã€é“¾è·¯è¿½è¸ªç­‰ã€‚

### A2 åˆ†æï¼ˆAnalyzeï¼‰
- **ç°çŠ¶**ï¼š
  - âœ… å·²å®ç°ï¼šåŸºç¡€åŠŸèƒ½å®ç°å’Œå•å…ƒæµ‹è¯•
  - ğŸ”„ éƒ¨åˆ†å®ç°ï¼šåŸºæœ¬çš„æ€§èƒ½ç‰¹æ€§
  - âŒ æœªå®ç°ï¼šé«˜çº§æ€§èƒ½ä¼˜åŒ–å’Œè§‚æµ‹æ€§åŠŸèƒ½
- **å·®è·**ï¼š
  - éœ€è¦ä¼˜åŒ–è´Ÿè½½å‡è¡¡ç®—æ³•æ€§èƒ½
  - éœ€è¦å¢å¼ºç¼“å­˜ç­–ç•¥å’Œå‘½ä¸­ç‡
  - éœ€è¦æ·»åŠ è¯¦ç»†çš„ç›‘æ§æŒ‡æ ‡å’Œé“¾è·¯è¿½è¸ª
- **çº¦æŸ**ï¼š
  - å¿…é¡»ä¿æŒä¸Javaç‰ˆæœ¬åŠŸèƒ½ä¸€è‡´
  - ç¬¦åˆGoè¯­è¨€å’ŒKratosæ¡†æ¶æœ€ä½³å®è·µ
  - ä¸å½±å“ç°æœ‰åŠŸèƒ½çš„ç¨³å®šæ€§
- **é£é™©**ï¼š
  - æŠ€æœ¯é£é™©ï¼šä¼˜åŒ–å¯èƒ½å¼•å…¥æ–°çš„bug
  - ä¸šåŠ¡é£é™©ï¼šæ€§èƒ½æå‡æ•ˆæœä¸æ˜æ˜¾
  - ä¾èµ–é£é™©ï¼šç›‘æ§ç»„ä»¶ä¾èµ–å˜æ›´

### A3 è®¾è®¡ï¼ˆArchitectï¼‰
- **æ¥å£å¥‘çº¦**ï¼š
  - **æ ¸å¿ƒæ¥å£**ï¼šæ€§èƒ½ç›‘æ§å’Œé“¾è·¯è¿½è¸ªæ¥å£
  - **æ ¸å¿ƒæ–¹æ³•**ï¼š
    - æ€§èƒ½ç›‘æ§ï¼š`RecordMetrics`ã€`GetMetrics`ã€`ExportMetrics`
    - é“¾è·¯è¿½è¸ªï¼š`StartSpan`ã€`EndSpan`ã€`AddEvent`
    - ç¼“å­˜ä¼˜åŒ–ï¼š`CacheStats`ã€`CacheOptimize`ã€`CacheEvict`
  - **è¾“å…¥è¾“å‡ºå‚æ•°åŠé”™è¯¯ç **ï¼š
    - ä½¿ç”¨æ ‡å‡†ç›‘æ§æŒ‡æ ‡æ ¼å¼ï¼ˆPrometheusã€OpenTelemetryï¼‰
    - æ”¯æŒé…ç½®é©±åŠ¨çš„æ€§èƒ½è°ƒä¼˜
    - æä¾›æ€§èƒ½åˆ†ææŠ¥å‘Š

- **æ¶æ„è®¾è®¡**ï¼š
  - é‡‡ç”¨è§‚å¯Ÿè€…æ¨¡å¼ï¼Œæ”¯æŒæ€§èƒ½äº‹ä»¶é€šçŸ¥
  - ä½¿ç”¨è£…é¥°å™¨æ¨¡å¼ï¼Œæ”¯æŒæ€§èƒ½ç›‘æ§åŒ…è£…
  - æ”¯æŒé…ç½®é©±åŠ¨çš„æ€§èƒ½è°ƒä¼˜ç­–ç•¥

- **æ ¸å¿ƒåŠŸèƒ½æ¨¡å—**ï¼š
  - æ€§èƒ½ç›‘æ§å™¨ï¼šæŒ‡æ ‡æ”¶é›†ã€æ€§èƒ½åˆ†æ
  - é“¾è·¯è¿½è¸ªå™¨ï¼šè¯·æ±‚é“¾è·¯ã€æ€§èƒ½åˆ†æ
  - ç¼“å­˜ä¼˜åŒ–å™¨ï¼šç­–ç•¥ä¼˜åŒ–ã€å‘½ä¸­ç‡æå‡
  - æ€§èƒ½åˆ†æå™¨ï¼šç“¶é¢ˆè¯†åˆ«ã€ä¼˜åŒ–å»ºè®®

- **æå°ä»»åŠ¡æ‹†åˆ†**ï¼š
  - T06-01ï¼šå®ç°æ€§èƒ½ç›‘æ§å™¨
  - T06-02ï¼šå®ç°é“¾è·¯è¿½è¸ªå™¨
  - T06-03ï¼šä¼˜åŒ–ç¼“å­˜ç­–ç•¥
  - T06-04ï¼šä¼˜åŒ–è´Ÿè½½å‡è¡¡ç®—æ³•
  - T06-05ï¼šå®ç°æ€§èƒ½åˆ†ææŠ¥å‘Š

### A4 è¡ŒåŠ¨ï¼ˆActï¼‰
#### T06-01ï¼šå®ç°æ€§èƒ½ç›‘æ§å™¨
```go
// route/state/metrics/performance_monitor.go
package metrics

import (
    "context"
    "sync"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// PerformanceMetrics æ€§èƒ½æŒ‡æ ‡
type PerformanceMetrics struct {
    // è¯·æ±‚ç›¸å…³æŒ‡æ ‡
    RequestTotal     prometheus.Counter
    RequestDuration  prometheus.Histogram
    RequestErrors    prometheus.Counter
    
    // ç¼“å­˜ç›¸å…³æŒ‡æ ‡
    CacheHits        prometheus.Counter
    CacheMisses      prometheus.Counter
    CacheSize        prometheus.Gauge
    
    // è´Ÿè½½å‡è¡¡ç›¸å…³æŒ‡æ ‡
    LoadBalancerRequests prometheus.Counter
    PodSelectionDuration prometheus.Histogram
    
    // å¥åº·æ£€æŸ¥ç›¸å…³æŒ‡æ ‡
    HealthCheckTotal     prometheus.Counter
    HealthCheckDuration  prometheus.Histogram
    HealthCheckFailures  prometheus.Counter
}

// PerformanceMonitor æ€§èƒ½ç›‘æ§å™¨
type PerformanceMonitor struct {
    mu sync.RWMutex
    
    metrics *PerformanceMetrics
    logger  log.Logger
    
    // è‡ªå®šä¹‰æŒ‡æ ‡
    customMetrics map[string]prometheus.Collector
}

// NewPerformanceMonitor åˆ›å»ºæ–°çš„æ€§èƒ½ç›‘æ§å™¨
func NewPerformanceMonitor(logger log.Logger) *PerformanceMonitor {
    metrics := &PerformanceMetrics{
        RequestTotal: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_requests_total",
            Help: "Total number of routing requests",
        }),
        RequestDuration: promauto.NewHistogram(prometheus.HistogramOpts{
            Name:    "stateful_route_request_duration_seconds",
            Help:    "Duration of routing requests",
            Buckets: prometheus.DefBuckets,
        }),
        RequestErrors: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_request_errors_total",
            Help: "Total number of routing request errors",
        }),
        CacheHits: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_cache_hits_total",
            Help: "Total number of cache hits",
        }),
        CacheMisses: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_cache_misses_total",
            Help: "Total number of cache misses",
        }),
        CacheSize: promauto.NewGauge(prometheus.GaugeOpts{
            Name: "stateful_route_cache_size",
            Help: "Current cache size",
        }),
        LoadBalancerRequests: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_load_balancer_requests_total",
            Help: "Total number of load balancer requests",
        }),
        PodSelectionDuration: promauto.NewHistogram(prometheus.HistogramOpts{
            Name:    "stateful_route_pod_selection_duration_seconds",
            Help:    "Duration of pod selection",
            Buckets: prometheus.DefBuckets,
        }),
        HealthCheckTotal: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_health_check_total",
            Help: "Total number of health checks",
        }),
        HealthCheckDuration: promauto.NewHistogram(prometheus.HistogramOpts{
            Name:    "stateful_route_health_check_duration_seconds",
            Help:    "Duration of health checks",
            Buckets: prometheus.DefBuckets,
        }),
        HealthCheckFailures: promauto.NewCounter(prometheus.CounterOpts{
            Name: "stateful_route_health_check_failures_total",
            Help: "Total number of health check failures",
        }),
    }
    
    return &PerformanceMonitor{
        metrics:       metrics,
        logger:        logger,
        customMetrics: make(map[string]prometheus.Collector),
    }
}

// RecordRequest è®°å½•è¯·æ±‚æŒ‡æ ‡
func (pm *PerformanceMonitor) RecordRequest(ctx context.Context, duration time.Duration, err error) {
    pm.metrics.RequestTotal.Inc()
    pm.metrics.RequestDuration.Observe(duration.Seconds())
    
    if err != nil {
        pm.metrics.RequestErrors.Inc()
    }
}

// RecordCacheHit è®°å½•ç¼“å­˜å‘½ä¸­
func (pm *PerformanceMonitor) RecordCacheHit(ctx context.Context) {
    pm.metrics.CacheHits.Inc()
}

// RecordCacheMiss è®°å½•ç¼“å­˜æœªå‘½ä¸­
func (pm *PerformanceMonitor) RecordCacheMiss(ctx context.Context) {
    pm.metrics.CacheMisses.Inc()
}

// UpdateCacheSize æ›´æ–°ç¼“å­˜å¤§å°
func (pm *PerformanceMonitor) UpdateCacheSize(ctx context.Context, size int) {
    pm.metrics.CacheSize.Set(float64(size))
}

// RecordLoadBalancerRequest è®°å½•è´Ÿè½½å‡è¡¡è¯·æ±‚
func (pm *PerformanceMonitor) RecordLoadBalancerRequest(ctx context.Context, duration time.Duration) {
    pm.metrics.LoadBalancerRequests.Inc()
    pm.metrics.PodSelectionDuration.Observe(duration.Seconds())
}

// RecordHealthCheck è®°å½•å¥åº·æ£€æŸ¥
func (pm *PerformanceMonitor) RecordHealthCheck(ctx context.Context, duration time.Duration, success bool) {
    pm.metrics.HealthCheckTotal.Inc()
    pm.metrics.HealthCheckDuration.Observe(duration.Seconds())
    
    if !success {
        pm.metrics.HealthCheckFailures.Inc()
    }
}

// GetCacheHitRate è·å–ç¼“å­˜å‘½ä¸­ç‡
func (pm *PerformanceMonitor) GetCacheHitRate(ctx context.Context) float64 {
    hits := pm.metrics.CacheHits.Get()
    misses := pm.metrics.CacheMisses.Get()
    total := hits + misses
    
    if total == 0 {
        return 0.0
    }
    
    return hits / total
}

// ExportMetrics å¯¼å‡ºæŒ‡æ ‡
func (pm *PerformanceMonitor) ExportMetrics(ctx context.Context) map[string]interface{} {
    return map[string]interface{}{
        "cache_hit_rate": pm.GetCacheHitRate(ctx),
        "request_total":   pm.metrics.RequestTotal.Get(),
        "request_errors":  pm.metrics.RequestErrors.Get(),
        "cache_size":      pm.metrics.CacheSize.Get(),
    }
}
```

#### T06-02ï¼šå®ç°é“¾è·¯è¿½è¸ªå™¨
```go
// route/state/tracing/request_tracer.go
package tracing

import (
    "context"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/trace"
)

// RequestTracer è¯·æ±‚é“¾è·¯è¿½è¸ªå™¨
type RequestTracer struct {
    tracer trace.Tracer
    logger log.Logger
}

// TraceInfo è¿½è¸ªä¿¡æ¯
type TraceInfo struct {
    TraceID    string
    SpanID     string
    ParentID   string
    Operation  string
    StartTime  time.Time
    EndTime    time.Time
    Attributes map[string]string
}

// NewRequestTracer åˆ›å»ºæ–°çš„è¯·æ±‚è¿½è¸ªå™¨
func NewRequestTracer(logger log.Logger) *RequestTracer {
    return &RequestTracer{
        tracer: otel.Tracer("stateful-route"),
        logger: logger,
    }
}

// StartSpan å¼€å§‹è¿½è¸ªspan
func (rt *RequestTracer) StartSpan(ctx context.Context, operation string, attributes map[string]string) (context.Context, trace.Span) {
    // è½¬æ¢å±æ€§
    attrs := make([]attribute.KeyValue, 0, len(attributes))
    for k, v := range attributes {
        attrs = append(attrs, attribute.String(k, v))
    }
    
    // åˆ›å»ºspan
    ctx, span := rt.tracer.Start(ctx, operation, trace.WithAttributes(attrs...))
    
    // è®°å½•å¼€å§‹æ—¶é—´
    span.SetAttributes(attribute.Int64("start_time", time.Now().UnixNano()))
    
    return ctx, span
}

// EndSpan ç»“æŸè¿½è¸ªspan
func (rt *RequestTracer) EndSpan(span trace.Span, err error) {
    if err != nil {
        span.SetStatus(trace.StatusError, err.Error())
        span.RecordError(err)
    } else {
        span.SetStatus(trace.StatusOK, "")
    }
    
    // è®°å½•ç»“æŸæ—¶é—´
    span.SetAttributes(attribute.Int64("end_time", time.Now().UnixNano()))
    
    span.End()
}

// AddEvent æ·»åŠ äº‹ä»¶
func (rt *RequestTracer) AddEvent(span trace.Span, name string, attributes map[string]string) {
    attrs := make([]attribute.KeyValue, 0, len(attributes))
    for k, v := range attributes {
        attrs = append(attrs, attribute.String(k, v))
    }
    
    span.AddEvent(name, trace.WithAttributes(attrs...))
}

// TraceRequest è¿½è¸ªè¯·æ±‚
func (rt *RequestTracer) TraceRequest(ctx context.Context, operation string, fn func(context.Context) error) error {
    ctx, span := rt.StartSpan(ctx, operation, nil)
    defer rt.EndSpan(span, nil)
    
    startTime := time.Now()
    err := fn(ctx)
    duration := time.Since(startTime)
    
    // è®°å½•è¯·æ±‚æŒç»­æ—¶é—´
    span.SetAttributes(attribute.Duration("duration", duration))
    
    if err != nil {
        rt.EndSpan(span, err)
    }
    
    return err
}

// GetTraceInfo è·å–è¿½è¸ªä¿¡æ¯
func (rt *RequestTracer) GetTraceInfo(ctx context.Context) *TraceInfo {
    span := trace.SpanFromContext(ctx)
    if span == nil {
        return nil
    }
    
    spanCtx := span.SpanContext()
    
    return &TraceInfo{
        TraceID:    spanCtx.TraceID().String(),
        SpanID:     spanCtx.SpanID().String(),
        ParentID:   "", // éœ€è¦ä»ä¸Šä¸‹æ–‡è·å–
        Operation:  span.Name(),
        StartTime:  time.Now(), // éœ€è¦ä»spanè·å–
        EndTime:    time.Now(), // éœ€è¦ä»spanè·å–
        Attributes: make(map[string]string),
    }
}
```

#### T06-03ï¼šä¼˜åŒ–ç¼“å­˜ç­–ç•¥
```go
// route/state/cache/cache_optimizer.go
package cache

import (
    "context"
    "sync"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
    "github.com/patrickmn/go-cache"
)

// CacheStrategy ç¼“å­˜ç­–ç•¥
type CacheStrategy int

const (
    StrategyLRU CacheStrategy = iota
    StrategyLFU
    StrategyTTL
    StrategyAdaptive
)

// CacheOptimizer ç¼“å­˜ä¼˜åŒ–å™¨
type CacheOptimizer struct {
    mu sync.RWMutex
    
    // ç¼“å­˜ç»Ÿè®¡
    stats *CacheStats
    
    // ç¼“å­˜ç­–ç•¥
    strategy CacheStrategy
    
    // è‡ªé€‚åº”å‚æ•°
    adaptiveParams *AdaptiveParams
    
    logger log.Logger
}

// CacheStats ç¼“å­˜ç»Ÿè®¡
type CacheStats struct {
    Hits        int64
    Misses      int64
    Evictions   int64
    Expirations int64
    Size        int
    MaxSize     int
}

// AdaptiveParams è‡ªé€‚åº”å‚æ•°
type AdaptiveParams struct {
    HitRateThreshold float64
    EvictionRate    float64
    TTLAdjustment   time.Duration
}

// NewCacheOptimizer åˆ›å»ºæ–°çš„ç¼“å­˜ä¼˜åŒ–å™¨
func NewCacheOptimizer(strategy CacheStrategy, logger log.Logger) *CacheOptimizer {
    return &CacheOptimizer{
        stats: &CacheStats{},
        strategy: strategy,
        adaptiveParams: &AdaptiveParams{
            HitRateThreshold: 0.8,
            EvictionRate:     0.1,
            TTLAdjustment:    5 * time.Minute,
        },
        logger: logger,
    }
}

// OptimizeCache ä¼˜åŒ–ç¼“å­˜
func (co *CacheOptimizer) OptimizeCache(ctx context.Context, c *cache.Cache) error {
    co.mu.Lock()
    defer co.mu.Unlock()
    
    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    co.updateStats(c)
    
    // æ ¹æ®ç­–ç•¥è¿›è¡Œä¼˜åŒ–
    switch co.strategy {
    case StrategyLRU:
        return co.optimizeLRU(ctx, c)
    case StrategyLFU:
        return co.optimizeLFU(ctx, c)
    case StrategyTTL:
        return co.optimizeTTL(ctx, c)
    case StrategyAdaptive:
        return co.optimizeAdaptive(ctx, c)
    default:
        return co.optimizeLRU(ctx, c)
    }
}

// optimizeLRU LRUä¼˜åŒ–ç­–ç•¥
func (co *CacheOptimizer) optimizeLRU(ctx context.Context, c *cache.Cache) error {
    // å¦‚æœç¼“å­˜å¤§å°è¶…è¿‡é˜ˆå€¼ï¼Œè¿›è¡ŒLRUæ¸…ç†
    if co.stats.Size > co.stats.MaxSize*8/10 {
        co.logger.Infof("LRU optimization: cache size %d exceeds threshold %d", co.stats.Size, co.stats.MaxSize*8/10)
        
        // æ¸…ç†æœ€ä¹…æœªä½¿ç”¨çš„é¡¹
        c.DeleteExpired()
        co.stats.Evictions++
    }
    
    return nil
}

// optimizeLFU LFUä¼˜åŒ–ç­–ç•¥
func (co *CacheOptimizer) optimizeLFU(ctx context.Context, c *cache.Cache) error {
    // LFUç­–ç•¥éœ€è¦è®°å½•è®¿é—®é¢‘ç‡
    // è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„LFUç®—æ³•
    return co.optimizeLRU(ctx, c)
}

// optimizeTTL TTLä¼˜åŒ–ç­–ç•¥
func (co *CacheOptimizer) optimizeTTL(ctx context.Context, c *cache.Cache) error {
    // æ ¹æ®å‘½ä¸­ç‡è°ƒæ•´TTL
    hitRate := co.getHitRate()
    
    if hitRate < co.adaptiveParams.HitRateThreshold {
        // å‘½ä¸­ç‡ä½ï¼Œå¢åŠ TTL
        co.logger.Infof("TTL optimization: hit rate %.2f below threshold %.2f, increasing TTL", hitRate, co.adaptiveParams.HitRateThreshold)
        // è¿™é‡Œåº”è¯¥è°ƒæ•´ç¼“å­˜çš„TTLè®¾ç½®
    }
    
    return nil
}

// optimizeAdaptive è‡ªé€‚åº”ä¼˜åŒ–ç­–ç•¥
func (co *CacheOptimizer) optimizeAdaptive(ctx context.Context, c *cache.Cache) error {
    hitRate := co.getHitRate()
    evictionRate := co.getEvictionRate()
    
    // æ ¹æ®å‘½ä¸­ç‡å’Œé©±é€ç‡è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´
    if hitRate < co.adaptiveParams.HitRateThreshold {
        // å‘½ä¸­ç‡ä½ï¼Œå¢åŠ ç¼“å­˜å¤§å°æˆ–TTL
        co.logger.Infof("Adaptive optimization: hit rate %.2f below threshold, adjusting cache parameters", hitRate)
    }
    
    if evictionRate > co.adaptiveParams.EvictionRate {
        // é©±é€ç‡é«˜ï¼Œå‡å°‘ç¼“å­˜å¤§å°æˆ–TTL
        co.logger.Infof("Adaptive optimization: eviction rate %.2f above threshold, adjusting cache parameters", evictionRate)
    }
    
    return nil
}

// updateStats æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (co *CacheOptimizer) updateStats(c *cache.Cache) {
    // è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    stats := c.Stats()
    
    co.stats.Hits = stats.Hits
    co.stats.Misses = stats.Misses
    co.stats.Evictions = stats.Evictions
    co.stats.Expirations = stats.Expirations
    co.stats.Size = stats.Size
    co.stats.MaxSize = stats.MaxSize
}

// getHitRate è·å–å‘½ä¸­ç‡
func (co *CacheOptimizer) getHitRate() float64 {
    total := co.stats.Hits + co.stats.Misses
    if total == 0 {
        return 0.0
    }
    return float64(co.stats.Hits) / float64(total)
}

// getEvictionRate è·å–é©±é€ç‡
func (co *CacheOptimizer) getEvictionRate() float64 {
    total := co.stats.Hits + co.stats.Misses
    if total == 0 {
        return 0.0
    }
    return float64(co.stats.Evictions) / float64(total)
}

// GetStats è·å–ç¼“å­˜ç»Ÿè®¡
func (co *CacheOptimizer) GetStats(ctx context.Context) *CacheStats {
    co.mu.RLock()
    defer co.mu.RUnlock()
    
    return &CacheStats{
        Hits:        co.stats.Hits,
        Misses:      co.stats.Misses,
        Evictions:   co.stats.Evictions,
        Expirations: co.stats.Expirations,
        Size:        co.stats.Size,
        MaxSize:     co.stats.MaxSize,
    }
}
```

#### T06-04ï¼šä¼˜åŒ–è´Ÿè½½å‡è¡¡ç®—æ³•
```go
// route/state/loadbalancer/optimized_load_balancer.go
package loadbalancer

import (
    "context"
    "fmt"
    "math/rand"
    "sync"
    "sync/atomic"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
)

// OptimizedLoadBalancer ä¼˜åŒ–çš„è´Ÿè½½å‡è¡¡å™¨
type OptimizedLoadBalancer struct {
    mu sync.RWMutex
    
    // è½®è¯¢è®¡æ•°å™¨
    roundRobinCounter uint64
    
    // åŠ æƒè½®è¯¢çŠ¶æ€
    weightedState map[int]*WeightedState
    
    // æœ€å°‘è¿æ¥çŠ¶æ€
    connectionState map[int]*ConnectionState
    
    // æ€§èƒ½ç»Ÿè®¡
    stats *LoadBalancerStats
    
    logger log.Logger
}

// WeightedState åŠ æƒçŠ¶æ€
type WeightedState struct {
    CurrentWeight int
    EffectiveWeight int
    PodIndex int
}

// ConnectionState è¿æ¥çŠ¶æ€
type ConnectionState struct {
    ConnectionCount int64
    LastUpdate     time.Time
    PodIndex       int
}

// LoadBalancerStats è´Ÿè½½å‡è¡¡å™¨ç»Ÿè®¡
type LoadBalancerStats struct {
    TotalRequests    int64
    StrategyRequests map[string]int64
    AverageLatency   time.Duration
    LastUpdate       time.Time
}

// NewOptimizedLoadBalancer åˆ›å»ºæ–°çš„ä¼˜åŒ–è´Ÿè½½å‡è¡¡å™¨
func NewOptimizedLoadBalancer(logger log.Logger) *OptimizedLoadBalancer {
    return &OptimizedLoadBalancer{
        weightedState:    make(map[int]*WeightedState),
        connectionState:  make(map[int]*ConnectionState),
        stats: &LoadBalancerStats{
            StrategyRequests: make(map[string]int64),
        },
        logger: logger,
    }
}

// SelectPod é€‰æ‹©podï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
func (olb *OptimizedLoadBalancer) SelectPod(ctx context.Context, pods []*PodInfo, strategy LoadBalancingStrategy) (int, error) {
    if len(pods) == 0 {
        return 0, fmt.Errorf("no available pods")
    }
    
    // è¿‡æ»¤å¥åº·çš„pod
    healthyPods := olb.filterHealthyPods(pods)
    if len(healthyPods) == 0 {
        return 0, fmt.Errorf("no healthy pods available")
    }
    
    startTime := time.Now()
    var podIndex int
    var err error
    
    // æ ¹æ®ç­–ç•¥é€‰æ‹©pod
    switch strategy {
    case StrategyRoundRobin:
        podIndex, err = olb.optimizedRoundRobin(healthyPods)
    case StrategyLeastConnections:
        podIndex, err = olb.optimizedLeastConnections(healthyPods)
    case StrategyWeightedRoundRobin:
        podIndex, err = olb.optimizedWeightedRoundRobin(healthyPods)
    case StrategyLeastResponseTime:
        podIndex, err = olb.optimizedLeastResponseTime(healthyPods)
    default:
        podIndex, err = olb.optimizedRoundRobin(healthyPods)
    }
    
    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    olb.updateStats(strategy, time.Since(startTime))
    
    return podIndex, err
}

// optimizedRoundRobin ä¼˜åŒ–çš„è½®è¯¢ç­–ç•¥
func (olb *OptimizedLoadBalancer) optimizedRoundRobin(pods []*PodInfo) (int, error) {
    // ä½¿ç”¨åŸå­æ“ä½œè¿›è¡Œè½®è¯¢
    counter := atomic.AddUint64(&olb.roundRobinCounter, 1)
    selectedIndex := int(counter % uint64(len(pods)))
    
    return pods[selectedIndex].Index, nil
}

// optimizedLeastConnections ä¼˜åŒ–çš„æœ€å°‘è¿æ¥ç­–ç•¥
func (olb *OptimizedLoadBalancer) optimizedLeastConnections(pods []*PodInfo) (int, error) {
    olb.mu.RLock()
    defer olb.mu.RUnlock()
    
    var minConnections int64 = 1<<63 - 1
    var selectedPod *PodInfo
    
    for _, pod := range pods {
        // è·å–è¿æ¥çŠ¶æ€
        state, exists := olb.connectionState[pod.Index]
        if !exists {
            // åˆå§‹åŒ–è¿æ¥çŠ¶æ€
            olb.connectionState[pod.Index] = &ConnectionState{
                ConnectionCount: 0,
                LastUpdate:     time.Now(),
                PodIndex:       pod.Index,
            }
            state = olb.connectionState[pod.Index]
        }
        
        if state.ConnectionCount < minConnections {
            minConnections = state.ConnectionCount
            selectedPod = pod
        }
    }
    
    if selectedPod == nil {
        return 0, fmt.Errorf("no pod selected")
    }
    
    return selectedPod.Index, nil
}

// optimizedWeightedRoundRobin ä¼˜åŒ–çš„åŠ æƒè½®è¯¢ç­–ç•¥
func (olb *OptimizedLoadBalancer) optimizedWeightedRoundRobin(pods []*PodInfo) (int, error) {
    olb.mu.Lock()
    defer olb.mu.Unlock()
    
    // åˆå§‹åŒ–åŠ æƒçŠ¶æ€
    for _, pod := range pods {
        if _, exists := olb.weightedState[pod.Index]; !exists {
            olb.weightedState[pod.Index] = &WeightedState{
                CurrentWeight:   pod.Weight,
                EffectiveWeight: pod.Weight,
                PodIndex:        pod.Index,
            }
        }
    }
    
    // é€‰æ‹©æƒé‡æœ€é«˜çš„pod
    var maxWeight int
    var selectedPod *PodInfo
    
    for _, pod := range pods {
        state := olb.weightedState[pod.Index]
        if state.CurrentWeight > maxWeight {
            maxWeight = state.CurrentWeight
            selectedPod = pod
        }
    }
    
    if selectedPod == nil {
        return 0, fmt.Errorf("no pod selected")
    }
    
    // æ›´æ–°æƒé‡
    state := olb.weightedState[selectedPod.Index]
    state.CurrentWeight -= olb.calculateTotalWeight(pods)
    
    // å¦‚æœæƒé‡ä¸ºè´Ÿï¼Œé‡ç½®ä¸ºæœ‰æ•ˆæƒé‡
    if state.CurrentWeight <= 0 {
        state.CurrentWeight += state.EffectiveWeight
    }
    
    return selectedPod.Index, nil
}

// optimizedLeastResponseTime ä¼˜åŒ–çš„æœ€å°‘å“åº”æ—¶é—´ç­–ç•¥
func (olb *OptimizedLoadBalancer) optimizedLeastResponseTime(pods []*PodInfo) (int, error) {
    if len(pods) == 0 {
        return 0, fmt.Errorf("no pods available")
    }
    
    minResponseTime := pods[0].ResponseTime
    selectedPod := pods[0]
    
    for _, pod := range pods[1:] {
        if pod.ResponseTime < minResponseTime {
            minResponseTime = pod.ResponseTime
            selectedPod = pod
        }
    }
    
    return selectedPod.Index, nil
}

// filterHealthyPods è¿‡æ»¤å¥åº·çš„pod
func (olb *OptimizedLoadBalancer) filterHealthyPods(pods []*PodInfo) []*PodInfo {
    healthyPods := make([]*PodInfo, 0, len(pods))
    for _, pod := range pods {
        if pod.IsHealthy {
            healthyPods = append(healthyPods, pod)
        }
    }
    return healthyPods
}

// calculateTotalWeight è®¡ç®—æ€»æƒé‡
func (olb *OptimizedLoadBalancer) calculateTotalWeight(pods []*PodInfo) int {
    total := 0
    for _, pod := range pods {
        total += pod.Weight
    }
    return total
}

// updateStats æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (olb *OptimizedLoadBalancer) updateStats(strategy LoadBalancingStrategy, latency time.Duration) {
    olb.mu.Lock()
    defer olb.mu.Unlock()
    
    atomic.AddInt64(&olb.stats.TotalRequests, 1)
    
    strategyName := strategy.String()
    olb.stats.StrategyRequests[strategyName]++
    
    // æ›´æ–°å¹³å‡å»¶è¿Ÿ
    if olb.stats.AverageLatency == 0 {
        olb.stats.AverageLatency = latency
    } else {
        olb.stats.AverageLatency = (olb.stats.AverageLatency + latency) / 2
    }
    
    olb.stats.LastUpdate = time.Now()
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (olb *OptimizedLoadBalancer) GetStats(ctx context.Context) *LoadBalancerStats {
    olb.mu.RLock()
    defer olb.mu.RUnlock()
    
    // è¿”å›å‰¯æœ¬
    stats := &LoadBalancerStats{
        TotalRequests:    atomic.LoadInt64(&olb.stats.TotalRequests),
        StrategyRequests: make(map[string]int64),
        AverageLatency:   olb.stats.AverageLatency,
        LastUpdate:       olb.stats.LastUpdate,
    }
    
    for k, v := range olb.stats.StrategyRequests {
        stats.StrategyRequests[k] = v
    }
    
    return stats
}
```

#### T06-05ï¼šå®ç°æ€§èƒ½åˆ†ææŠ¥å‘Š
```go
// route/state/analysis/performance_analyzer.go
package analysis

import (
    "context"
    "fmt"
    "sync"
    "time"
    
    "github.com/go-kratos/kratos/v2/log"
)

// PerformanceAnalyzer æ€§èƒ½åˆ†æå™¨
type PerformanceAnalyzer struct {
    mu sync.RWMutex
    
    // æ€§èƒ½æ•°æ®æ”¶é›†å™¨
    collectors map[string]PerformanceCollector
    
    // åˆ†æè§„åˆ™
    rules []AnalysisRule
    
    // åˆ†æç»“æœ
    results []AnalysisResult
    
    logger log.Logger
}

// PerformanceCollector æ€§èƒ½æ•°æ®æ”¶é›†å™¨æ¥å£
type PerformanceCollector interface {
    Collect(ctx context.Context) (*PerformanceData, error)
    GetName() string
}

// PerformanceData æ€§èƒ½æ•°æ®
type PerformanceData struct {
    Timestamp   time.Time
    Collector   string
    Metrics     map[string]float64
    RawData     interface{}
}

// AnalysisRule åˆ†æè§„åˆ™
type AnalysisRule struct {
    Name        string
    Description string
    Threshold   float64
    Severity    Severity
    Condition   func(*PerformanceData) bool
}

// AnalysisResult åˆ†æç»“æœ
type AnalysisResult struct {
    Timestamp   time.Time
    Rule        string
    Severity    Severity
    Message     string
    Data        *PerformanceData
    Suggestions []string
}

// Severity ä¸¥é‡ç¨‹åº¦
type Severity int

const (
    SeverityLow Severity = iota
    SeverityMedium
    SeverityHigh
    SeverityCritical
)

// NewPerformanceAnalyzer åˆ›å»ºæ–°çš„æ€§èƒ½åˆ†æå™¨
func NewPerformanceAnalyzer(logger log.Logger) *PerformanceAnalyzer {
    analyzer := &PerformanceAnalyzer{
        collectors: make(map[string]PerformanceCollector),
        rules:      make([]AnalysisRule, 0),
        results:    make([]AnalysisResult, 0),
        logger:     logger,
    }
    
    // æ·»åŠ é»˜è®¤åˆ†æè§„åˆ™
    analyzer.addDefaultRules()
    
    return analyzer
}

// AddCollector æ·»åŠ æ€§èƒ½æ•°æ®æ”¶é›†å™¨
func (pa *PerformanceAnalyzer) AddCollector(collector PerformanceCollector) error {
    pa.mu.Lock()
    defer pa.mu.Unlock()
    
    name := collector.GetName()
    if _, exists := pa.collectors[name]; exists {
        return fmt.Errorf("collector %s already exists", name)
    }
    
    pa.collectors[name] = collector
    pa.logger.Infof("Added performance collector: %s", name)
    
    return nil
}

// AddRule æ·»åŠ åˆ†æè§„åˆ™
func (pa *PerformanceAnalyzer) AddRule(rule AnalysisRule) error {
    pa.mu.Lock()
    defer pa.mu.Unlock()
    
    pa.rules = append(pa.rules, rule)
    pa.logger.Infof("Added analysis rule: %s", rule.Name)
    
    return nil
}

// Analyze æ‰§è¡Œæ€§èƒ½åˆ†æ
func (pa *PerformanceAnalyzer) Analyze(ctx context.Context) ([]AnalysisResult, error) {
    pa.mu.Lock()
    defer pa.mu.Unlock()
    
    var allResults []AnalysisResult
    
    // æ”¶é›†æ‰€æœ‰æ€§èƒ½æ•°æ®
    for name, collector := range pa.collectors {
        data, err := collector.Collect(ctx)
        if err != nil {
            pa.logger.Errorf("Failed to collect data from %s: %v", name, err)
            continue
        }
        
        // åº”ç”¨åˆ†æè§„åˆ™
        results := pa.applyRules(data)
        allResults = append(allResults, results...)
    }
    
    // ä¿å­˜åˆ†æç»“æœ
    pa.results = append(pa.results, allResults...)
    
    // é™åˆ¶ç»“æœæ•°é‡
    if len(pa.results) > 1000 {
        pa.results = pa.results[len(pa.results)-1000:]
    }
    
    pa.logger.Infof("Performance analysis completed: %d results generated", len(allResults))
    
    return allResults, nil
}

// applyRules åº”ç”¨åˆ†æè§„åˆ™
func (pa *PerformanceAnalyzer) applyRules(data *PerformanceData) []AnalysisResult {
    var results []AnalysisResult
    
    for _, rule := range pa.rules {
        if rule.Condition(data) {
            result := AnalysisResult{
                Timestamp:   time.Now(),
                Rule:        rule.Name,
                Severity:    rule.Severity,
                Message:     rule.Description,
                Data:        data,
                Suggestions: pa.generateSuggestions(rule, data),
            }
            
            results = append(results, result)
        }
    }
    
    return results
}

// generateSuggestions ç”Ÿæˆä¼˜åŒ–å»ºè®®
func (pa *PerformanceAnalyzer) generateSuggestions(rule AnalysisRule, data *PerformanceData) []string {
    var suggestions []string
    
    switch rule.Name {
    case "cache_hit_rate_low":
        suggestions = append(suggestions, "å¢åŠ ç¼“å­˜å¤§å°", "ä¼˜åŒ–ç¼“å­˜ç­–ç•¥", "æ£€æŸ¥ç¼“å­˜é”®è®¾è®¡")
    case "response_time_high":
        suggestions = append(suggestions, "ä¼˜åŒ–ç®—æ³•å®ç°", "å¢åŠ ç¼“å­˜", "æ£€æŸ¥ä¾èµ–æœåŠ¡æ€§èƒ½")
    case "error_rate_high":
        suggestions = append(suggestions, "æ£€æŸ¥é”™è¯¯æ—¥å¿—", "ä¼˜åŒ–é”™è¯¯å¤„ç†", "å¢åŠ é‡è¯•æœºåˆ¶")
    case "memory_usage_high":
        suggestions = append(suggestions, "æ£€æŸ¥å†…å­˜æ³„æ¼", "ä¼˜åŒ–æ•°æ®ç»“æ„", "å¢åŠ åƒåœ¾å›æ”¶")
    default:
        suggestions = append(suggestions, "æ£€æŸ¥ç³»ç»Ÿé…ç½®", "ä¼˜åŒ–ä»£ç å®ç°", "å¢åŠ ç›‘æ§æŒ‡æ ‡")
    }
    
    return suggestions
}

// addDefaultRules æ·»åŠ é»˜è®¤åˆ†æè§„åˆ™
func (pa *PerformanceAnalyzer) addDefaultRules() {
    // ç¼“å­˜å‘½ä¸­ç‡è§„åˆ™
    pa.AddRule(AnalysisRule{
        Name:        "cache_hit_rate_low",
        Description: "ç¼“å­˜å‘½ä¸­ç‡ä½äºé˜ˆå€¼",
        Threshold:   0.8,
        Severity:    SeverityMedium,
        Condition: func(data *PerformanceData) bool {
            if hitRate, exists := data.Metrics["cache_hit_rate"]; exists {
                return hitRate < 0.8
            }
            return false
        },
    })
    
    // å“åº”æ—¶é—´è§„åˆ™
    pa.AddRule(AnalysisRule{
        Name:        "response_time_high",
        Description: "å“åº”æ—¶é—´è¿‡é«˜",
        Threshold:   100, // æ¯«ç§’
        Severity:    SeverityHigh,
        Condition: func(data *PerformanceData) bool {
            if responseTime, exists := data.Metrics["response_time"]; exists {
                return responseTime > 100
            }
            return false
        },
    })
    
    // é”™è¯¯ç‡è§„åˆ™
    pa.AddRule(AnalysisRule{
        Name:        "error_rate_high",
        Description: "é”™è¯¯ç‡è¿‡é«˜",
        Threshold:   0.05, // 5%
        Severity:    SeverityCritical,
        Condition: func(data *PerformanceData) bool {
            if errorRate, exists := data.Metrics["error_rate"]; exists {
                return errorRate > 0.05
            }
            return false
        },
    })
}

// GetResults è·å–åˆ†æç»“æœ
func (pa *PerformanceAnalyzer) GetResults(ctx context.Context, severity Severity) []AnalysisResult {
    pa.mu.RLock()
    defer pa.mu.RUnlock()
    
    var filteredResults []AnalysisResult
    
    for _, result := range pa.results {
        if result.Severity >= severity {
            filteredResults = append(filteredResults, result)
        }
    }
    
    return filteredResults
}

// GenerateReport ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
func (pa *PerformanceAnalyzer) GenerateReport(ctx context.Context) (*PerformanceReport, error) {
    results, err := pa.Analyze(ctx)
    if err != nil {
        return nil, fmt.Errorf("failed to analyze performance: %w", err)
    }
    
    report := &PerformanceReport{
        Timestamp:     time.Now(),
        Summary:       pa.generateSummary(results),
        CriticalIssues: pa.filterResultsBySeverity(results, SeverityCritical),
        HighIssues:    pa.filterResultsBySeverity(results, SeverityHigh),
        MediumIssues:  pa.filterResultsBySeverity(results, SeverityMedium),
        LowIssues:     pa.filterResultsBySeverity(results, SeverityLow),
        Suggestions:   pa.generateOverallSuggestions(results),
    }
    
    return report, nil
}

// PerformanceReport æ€§èƒ½åˆ†ææŠ¥å‘Š
type PerformanceReport struct {
    Timestamp      time.Time
    Summary        string
    CriticalIssues []AnalysisResult
    HighIssues     []AnalysisResult
    MediumIssues   []AnalysisResult
    LowIssues      []AnalysisResult
    Suggestions    []string
}

// generateSummary ç”Ÿæˆæ‘˜è¦
func (pa *PerformanceAnalyzer) generateSummary(results []AnalysisResult) string {
    total := len(results)
    critical := len(pa.filterResultsBySeverity(results, SeverityCritical))
    high := len(pa.filterResultsBySeverity(results, SeverityHigh))
    
    if critical > 0 {
        return fmt.Sprintf("å‘ç° %d ä¸ªä¸¥é‡é—®é¢˜ï¼Œ%d ä¸ªé«˜çº§é—®é¢˜ï¼Œå»ºè®®ç«‹å³å¤„ç†", critical, high)
    } else if high > 0 {
        return fmt.Sprintf("å‘ç° %d ä¸ªé«˜çº§é—®é¢˜ï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†", high)
    } else {
        return fmt.Sprintf("ç³»ç»Ÿæ€§èƒ½æ­£å¸¸ï¼Œå…±åˆ†æ %d ä¸ªæŒ‡æ ‡", total)
    }
}

// filterResultsBySeverity æŒ‰ä¸¥é‡ç¨‹åº¦è¿‡æ»¤ç»“æœ
func (pa *PerformanceAnalyzer) filterResultsBySeverity(results []AnalysisResult, severity Severity) []AnalysisResult {
    var filtered []AnalysisResult
    for _, result := range results {
        if result.Severity == severity {
            filtered = append(filtered, result)
        }
    }
    return filtered
}

// generateOverallSuggestions ç”Ÿæˆæ•´ä½“ä¼˜åŒ–å»ºè®®
func (pa *PerformanceAnalyzer) generateOverallSuggestions(results []AnalysisResult) []string {
    var suggestions []string
    
    // æ ¹æ®é—®é¢˜ç±»å‹ç”Ÿæˆå»ºè®®
    hasCacheIssues := false
    hasPerformanceIssues := false
    hasErrorIssues := false
    
    for _, result := range results {
        switch result.Rule {
        case "cache_hit_rate_low":
            hasCacheIssues = true
        case "response_time_high":
            hasPerformanceIssues = true
        case "error_rate_high":
            hasErrorIssues = true
        }
    }
    
    if hasCacheIssues {
        suggestions = append(suggestions, "ä¼˜åŒ–ç¼“å­˜ç­–ç•¥å’Œé…ç½®")
    }
    
    if hasPerformanceIssues {
        suggestions = append(suggestions, "ä¼˜åŒ–ç®—æ³•å®ç°å’Œæ•°æ®ç»“æ„")
    }
    
    if hasErrorIssues {
        suggestions = append(suggestions, "åŠ å¼ºé”™è¯¯å¤„ç†å’Œç›‘æ§")
    }
    
    if len(suggestions) == 0 {
        suggestions = append(suggestions, "ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œç»§ç»­ä¿æŒ")
    }
    
    return suggestions
}
```

### A5 éªŒè¯ï¼ˆAssureï¼‰
- **æµ‹è¯•ç”¨ä¾‹**ï¼š
  - æ€§èƒ½ç›‘æ§åŠŸèƒ½æµ‹è¯•
  - é“¾è·¯è¿½è¸ªåŠŸèƒ½æµ‹è¯•
  - ç¼“å­˜ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•
  - è´Ÿè½½å‡è¡¡ä¼˜åŒ–æµ‹è¯•
  - æ€§èƒ½åˆ†æåŠŸèƒ½æµ‹è¯•
- **æ€§èƒ½éªŒè¯**ï¼š
  - æ€§èƒ½æå‡åŸºå‡†æµ‹è¯•
  - ç›‘æ§å¼€é”€æµ‹è¯•
  - ç¼“å­˜å‘½ä¸­ç‡æµ‹è¯•
- **å›å½’æµ‹è¯•**ï¼š
  - ç¡®ä¿ä¼˜åŒ–ä¸å½±å“ç°æœ‰åŠŸèƒ½
- **æµ‹è¯•ç»“æœ**ï¼š
  - æ€§èƒ½æå‡ â‰¥ 20%
  - ç›‘æ§å¼€é”€ < 5%
  - ç¼“å­˜å‘½ä¸­ç‡æå‡ â‰¥ 10%

### A6 è¿­ä»£ï¼ˆAdvanceï¼‰
- æ€§èƒ½ä¼˜åŒ–ï¼šè¿›ä¸€æ­¥ç®—æ³•ä¼˜åŒ–ã€ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
- åŠŸèƒ½æ‰©å±•ï¼šæ”¯æŒæ›´å¤šç›‘æ§æŒ‡æ ‡ã€åˆ†æè§„åˆ™
- è§‚æµ‹æ€§å¢å¼ºï¼šæ·»åŠ å‘Šè­¦æœºåˆ¶ã€è‡ªåŠ¨ä¼˜åŒ–å»ºè®®
- ä¸‹ä¸€æ­¥ä»»åŠ¡é“¾æ¥ï¼šå®Œæˆæ•´ä¸ªæ¨¡å—çš„6Aè¿ç§»

### ğŸ“‹ è´¨é‡æ£€æŸ¥
- [ ] ä»£ç è´¨é‡æ£€æŸ¥å®Œæˆ
- [ ] æ–‡æ¡£è´¨é‡æ£€æŸ¥å®Œæˆ
- [ ] æµ‹è¯•è´¨é‡æ£€æŸ¥å®Œæˆ

### ğŸ“‹ å®Œæˆæ€»ç»“
[æ€»ç»“ä»»åŠ¡å®Œæˆæƒ…å†µ]
